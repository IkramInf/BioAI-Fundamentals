# Human Genome Reconstruction: A Practical Guide from FASTQ to Assembly

## Author's Note
This tutorial walks through a complete, reproducible workflow for reconstructing a human genome from raw sequencing reads. We'll cover both single-end and paired-end data, with real commands you can run and practical explanations of tool choices.

---

## Table of Contents
1. [Theoretical Background](#theoretical-background)
2. [Workflow Overview](#workflow-overview)
3. [Environment Setup](#environment-setup)
4. [Dataset Preparation](#dataset-preparation)
5. [Quality Control](#quality-control)
6. [Read Trimming and Filtering](#read-trimming-and-filtering)
7. [Genome Assembly](#genome-assembly)
8. [Assembly Quality Assessment](#assembly-quality-assessment)
9. [Scaffolding and Gap Filling](#scaffolding-and-gap-filling)
10. [Final Validation](#final-validation)

---

## 1. Theoretical Background

### What is Genome Assembly?

Genome assembly is the process of reconstructing a genome sequence from short DNA fragments (reads) generated by sequencing machines. Think of it as solving a massive jigsaw puzzle where:
- You have millions of small pieces (reads)
- Pieces overlap but you don't know how
- Some pieces are missing or damaged
- You need to reconstruct the complete picture (genome)

### Single-End vs Paired-End Sequencing

**Single-End (SE):**
- Sequences DNA fragments from one direction only
- Cheaper and faster
- Less information for assembly
- Read length: typically 50-150 bp

**Paired-End (PE):**
- Sequences both ends of DNA fragments
- You know the approximate distance between paired reads (insert size)
- Better for resolving repeats and structural variants
- More expensive but vastly superior for assembly
- Read length: typically 2×100 to 2×300 bp

**Why PE is almost always better for genome assembly:**
- Insert size constraint helps scaffold contigs
- Spans repetitive regions better
- Detects structural variations
- Higher effective coverage

### Assembly Approaches

**De Bruijn Graph (DBG) Assemblers:**
- Break reads into k-mers (substrings of length k)
- Build a graph where edges are k-mers
- Find paths through the graph
- Examples: SPAdes, MEGAHIT, Velvet
- **Pros:** Memory efficient, handles high coverage well
- **Cons:** Sensitive to sequencing errors, struggles with repeats

**Overlap-Layout-Consensus (OLC) Assemblers:**
- Find overlaps between all reads
- Build layout graph
- Generate consensus sequences
- Examples: Canu, Flye (long reads), Celera
- **Pros:** Better for long reads, handles repeats better
- **Cons:** Computationally expensive, high memory usage

**Hybrid Assemblers:**
- Combine short and long reads
- Use short reads for accuracy, long reads for continuity
- Examples: SPAdes hybrid mode, MaSuRCA
- **Best choice for production assemblies when you have both data types**

---

## 2. Workflow Overview

```
Raw FASTQ Files
    ↓
Quality Control (FastQC)
    ↓
Adapter Trimming & Quality Filtering (Trimmomatic/fastp)
    ↓
Error Correction (lighter/Musket)
    ↓
De novo Assembly (SPAdes/MEGAHIT)
    ↓
Assembly Quality Assessment (QUAST, BUSCO)
    ↓
Scaffolding (optional: SSPACE, BESST)
    ↓
Gap Filling (GapCloser, Sealer)
    ↓
Final Validation & Polishing
```

---

## 3. Environment Setup

### System Requirements

For human genome assembly, you need serious computational resources:
- **CPU:** 32+ cores recommended (minimum 16)
- **RAM:** 128-256 GB (human genome is ~3 Gb, assemblers need 50-80× in RAM)
- **Storage:** 500 GB - 2 TB (intermediate files are huge)
- **Time:** 24-72 hours for complete assembly

### Software Installation

I recommend using conda/mamba for reproducibility:

```bash
# Create dedicated environment
conda create -n genome_assembly python=3.9
conda activate genome_assembly

# Install tools
conda install -c bioconda \
    fastqc=0.12.1 \
    multiqc=1.14 \
    fastp=0.23.4 \
    spades=3.15.5 \
    quast=5.2.0 \
    busco=5.4.7 \
    samtools=1.17 \
    bwa=0.7.17 \
    picard=2.27.5

# Verify installations
fastqc --version
spades.py --version
quast.py --version
```

**Why these tools?**
- **FastQC:** Industry standard, comprehensive QC metrics
- **fastp:** Faster than Trimmomatic, built-in QC, single tool for trimming
- **SPAdes:** Best general-purpose assembler for Illumina data, excellent quality
- **QUAST:** Standard for assembly statistics
- **BUSCO:** Assesses biological completeness using conserved genes

---

## 4. Dataset Preparation

### Option A: Using Public Data (Recommended for Learning)

We'll use a human genome subset for this tutorial. Full human genome assembly takes days and hundreds of GB of data.

```bash
# Create project structure
mkdir -p genome_assembly/{raw_data,qc,trimmed,assembly,results}
cd genome_assembly

# Download NA12878 human genome subset (chromosome 22, ~51 Mb)
# Using 30× coverage paired-end data
wget -P raw_data/ \
    ftp://ftp.sra.ebi.ac.uk/vol1/fastq/SRR622/SRR622461/SRR622461_1.fastq.gz \
    ftp://ftp.sra.ebi.ac.uk/vol1/fastq/SRR622/SRR622461/SRR622461_2.fastq.gz

# For single-end example (smaller dataset)
wget -P raw_data/ \
    ftp://ftp.sra.ebi.ac.uk/vol1/fastq/SRR622/SRR622462/SRR622462.fastq.gz
```

### Option B: Your Own Data

```bash
# Place your FASTQ files in raw_data/
# Paired-end: sample_R1.fastq.gz, sample_R2.fastq.gz
# Single-end: sample.fastq.gz

# Verify file integrity
md5sum raw_data/*.fastq.gz > checksums.txt
```

### Quick Data Inspection

```bash
# Check read count
echo "Total reads in R1:"
zcat raw_data/SRR622461_1.fastq.gz | echo $((`wc -l`/4))

# Check read length
zcat raw_data/SRR622461_1.fastq.gz | head -n 2 | tail -n 1 | awk '{print length($0)}'

# Estimate coverage (for human chr22: ~51 Mb)
READ_COUNT=$(zcat raw_data/SRR622461_1.fastq.gz | echo $((`wc -l`/4)))
READ_LENGTH=101
GENOME_SIZE=51000000
COVERAGE=$((READ_COUNT * READ_LENGTH * 2 / GENOME_SIZE))
echo "Estimated coverage: ${COVERAGE}×"
```

**Coverage considerations:**
- **20-30×:** Minimum for decent assembly
- **50-100×:** Sweet spot for quality vs cost
- **>100×:** Diminishing returns, wastes resources

---

## 5. Quality Control

### Why QC First?

You need to understand your data before processing:
- Adapter contamination?
- Quality drop-off patterns?
- GC bias?
- Overrepresented sequences?
- Sequencing errors?

**These issues directly affect assembly quality.**

### Running FastQC

```bash
# Paired-end QC
fastqc -t 8 -o qc/ raw_data/SRR622461_1.fastq.gz raw_data/SRR622461_2.fastq.gz

# Single-end QC
fastqc -t 8 -o qc/ raw_data/SRR622462.fastq.gz

# Aggregate reports with MultiQC
multiqc qc/ -o qc/
```

**Parameter explanation:**
- `-t 8`: Use 8 threads (FastQC is parallelizable)
- `-o qc/`: Output directory

### Interpreting QC Results

Open `qc/multiqc_report.html` in a browser. Key metrics to check:

1. **Per Base Sequence Quality**
   - Should be >30 (Phred score) across most of read
   - Common to see drop at 3' end
   - **Action:** If quality drops below 20, trim those bases

2. **Per Sequence Quality Scores**
   - Most reads should have mean quality >30
   - **Action:** If significant low-quality peak, consider stricter filtering

3. **Adapter Content**
   - Should be <1% adapters
   - **Action:** If >5%, must trim adapters

4. **GC Content**
   - Should match expected distribution (human ~41%)
   - Sharp peaks indicate contamination
   - **Action:** Investigate unexpected peaks

5. **Sequence Duplication Levels**
   - High duplication (>50%) can indicate:
     - PCR bias (bad)
     - High coverage (good)
     - Contamination (bad)
   - **Action:** For assembly, moderate duplication is acceptable

---

## 6. Read Trimming and Filtering

### Why fastp over Trimmomatic?

**fastp advantages:**
- 2-5× faster
- Automatic adapter detection
- Built-in QC reporting
- Single tool for all trimming operations
- Better algorithm for quality filtering

**Trimmomatic advantages:**
- More mature, widely cited
- More fine-grained control
- Better documented for edge cases

**Verdict:** Use fastp unless you have specific Trimmomatic requirements.

### Paired-End Trimming

```bash
fastp \
    -i raw_data/SRR622461_1.fastq.gz \
    -I raw_data/SRR622461_2.fastq.gz \
    -o trimmed/SRR622461_1.trim.fastq.gz \
    -O trimmed/SRR622461_2.trim.fastq.gz \
    --detect_adapter_for_pe \
    --qualified_quality_phred 20 \
    --unqualified_percent_limit 40 \
    --length_required 50 \
    --thread 8 \
    --html trimmed/fastp_report.html \
    --json trimmed/fastp_report.json
```

**Parameter breakdown:**

| Parameter | Value | Why? |
|-----------|-------|------|
| `--detect_adapter_for_pe` | auto | Automatically detects Illumina adapters. Saves you from specifying. |
| `--qualified_quality_phred` | 20 | Bases with Q≥20 are "qualified". Q20 = 1% error rate, good balance. |
| `--unqualified_percent_limit` | 40 | If >40% bases are unqualified, discard read. Prevents garbage reads. |
| `--length_required` | 50 | Minimum read length after trimming. Too short reads hurt assembly. |
| `--thread` | 8 | Parallel processing. Use available cores. |

**How to choose these values:**

- **Quality threshold (20 vs 30):**
  - Q30 (99.9% accuracy): More stringent, keeps fewer reads
  - Q20 (99% accuracy): More permissive, keeps more data
  - **For assembly:** Q20 is usually sufficient, modern assemblers handle some errors
  - **For variant calling:** Use Q30

- **Length threshold:**
  - Should be at least 1/3 of original read length
  - For 100bp reads: 50bp minimum
  - For 150bp reads: 75bp minimum
  - Too short reads create ambiguous overlaps

### Single-End Trimming

```bash
fastp \
    -i raw_data/SRR622462.fastq.gz \
    -o trimmed/SRR622462.trim.fastq.gz \
    --adapter_sequence AGATCGGAAGAGC \
    --qualified_quality_phred 20 \
    --unqualified_percent_limit 40 \
    --length_required 50 \
    --thread 8 \
    --html trimmed/fastp_report_se.html
```

### Post-Trimming QC

```bash
# Run FastQC on trimmed data
fastqc -t 8 -o qc/ trimmed/*.trim.fastq.gz
multiqc qc/ -o qc/ --filename multiqc_post_trim
```

**Compare before/after:**
- Quality scores should improve
- Adapter content should drop to <1%
- Read length distribution shifts left (expected)
- Should retain >80% of reads (if not, parameters too strict)

---

## 7. Genome Assembly

### Assembler Selection

**For Illumina short reads:**

| Assembler | Best For | Speed | Memory | Quality |
|-----------|----------|-------|--------|---------|
| **SPAdes** | General purpose, small-medium genomes | Moderate | High | Excellent |
| **MEGAHIT** | Large genomes, limited RAM | Fast | Low | Good |
| **ABySS** | Very large genomes, HPC | Fast | Moderate | Good |
| **SOAPdenovo2** | Large genomes, older but stable | Moderate | High | Good |

**Why we're using SPAdes:**
- Best quality assemblies for Illumina data (proven in multiple benchmarks)
- Handles uneven coverage well
- Built-in error correction
- Supports paired-end, mate-pairs, and single-end
- Active development and support
- **Con:** Memory hungry (needs ~10-15× genome size in RAM)

**When to use MEGAHIT instead:**
- Limited RAM (<128 GB for human genome)
- Prioritize speed over quality
- Very large genomes (>10 Gb)

### Assembly: Paired-End Reads

```bash
spades.py \
    -1 trimmed/SRR622461_1.trim.fastq.gz \
    -2 trimmed/SRR622461_2.trim.fastq.gz \
    -o assembly/spades_pe \
    --threads 16 \
    --memory 100 \
    -k 21,33,55,77 \
    --careful
```

**Critical parameters explained:**

**1. k-mer size (`-k 21,33,55,77`):**
- SPAdes uses multiple k-mer sizes iteratively
- **Smaller k-mers (21,33):**
  - Better for low coverage regions
  - More sensitive to sequencing errors
  - Create more fragmented assemblies
- **Larger k-mers (55,77):**
  - Better for high coverage regions
  - More specific, fewer false overlaps
  - Resolve repeats better
  - Create longer contigs

**How to choose k-mer sizes:**
```
General rule: k < read_length
For 100bp reads: use k ≤ 77
For 150bp reads: use k ≤ 127

Start small (k=21): captures low-coverage regions
End large (k=77): maximizes contig length
Step by ~1.5×: balances computation vs information
```

**2. `--careful` mode:**
- Runs MismatchCorrector after assembly
- Reduces small mismatches and indels
- Takes ~20% more time
- **Always use for publication-quality assemblies**
- **Omit for draft assemblies to save time**

**3. `--threads` and `--memory`:**
- SPAdes will use all specified threads
- Memory limit prevents crashes (conservative estimate)
- For human chr22: 16 threads, 100 GB is comfortable
- For full human genome: 32 threads, 250 GB minimum

### Assembly: Single-End Reads

```bash
spades.py \
    -s trimmed/SRR622462.trim.fastq.gz \
    -o assembly/spades_se \
    --threads 16 \
    --memory 100 \
    -k 21,33,55 \
    --careful
```

**Note:** Single-end assemblies produce:
- More fragmented results (higher contig count)
- Shorter contigs
- More ambiguous repeat resolution
- **Only use SE when PE is not available**

### Assembly: Hybrid (PE + Long Reads)

If you have both Illumina and long reads (Oxford Nanopore/PacBio):

```bash
spades.py \
    -1 trimmed/SRR622461_1.trim.fastq.gz \
    -2 trimmed/SRR622461_2.trim.fastq.gz \
    --nanopore long_reads.fastq.gz \
    -o assembly/spades_hybrid \
    --threads 16 \
    --memory 150 \
    -k 21,33,55,77 \
    --careful
```

**Why hybrid is superior:**
- Long reads provide scaffolding
- Short reads provide accuracy
- Best of both worlds
- Can achieve chromosome-level assemblies

### Alternative: MEGAHIT (Low Memory Option)

```bash
megahit \
    -1 trimmed/SRR622461_1.trim.fastq.gz \
    -2 trimmed/SRR622461_2.trim.fastq.gz \
    -o assembly/megahit_pe \
    --threads 16 \
    --memory 0.8 \
    --k-min 21 \
    --k-max 77 \
    --k-step 12
```

**MEGAHIT vs SPAdes comparison:**

| Metric | MEGAHIT | SPAdes |
|--------|---------|--------|
| Runtime | 2-4 hours | 12-24 hours |
| Memory | 30-50 GB | 100-200 GB |
| N50 | Good | Better |
| Misassemblies | Slightly more | Fewer |
| Ease of use | Simpler | More options |

### Monitoring Assembly Progress

```bash
# SPAdes logs everything
tail -f assembly/spades_pe/spades.log

# Key stages to watch:
# 1. Error correction (BayesHammer)
# 2. k-mer counting
# 3. Graph construction
# 4. Contig extraction
# 5. Repeat resolution
# 6. MismatchCorrector (if --careful)
```

---

## 8. Assembly Quality Assessment

### Understanding Assembly Metrics

**Key metrics:**

1. **Number of contigs:** Lower is better
   - Good: <1,000 for bacterial genome
   - Acceptable: <10,000 for human chr22
   - Poor: >50,000

2. **N50:** Length at which 50% of assembly is in contigs of this size or larger
   - Longer is better
   - For human chr22: aim for >100 kb
   - **Example:** If N50 = 50 kb, half the assembly is in contigs ≥50 kb

3. **L50:** Number of contigs that contain 50% of assembly
   - Lower is better
   - Indicates contiguity

4. **Largest contig:** Longest single sequence
   - Should approach chromosome size ideally
   - For chr22: ideal is ~51 Mb (whole chromosome)

5. **Total assembly size:** Should match expected genome size
   - Human chr22: ~51 Mb
   - If much larger: contamination or duplication
   - If much smaller: missing sequences

### QUAST: Statistical Assessment

```bash
# Basic QUAST analysis
quast.py \
    assembly/spades_pe/contigs.fasta \
    -o results/quast_pe \
    --threads 8 \
    --min-contig 500 \
    --labels "SPAdes_PE"

# With reference (if available)
quast.py \
    assembly/spades_pe/contigs.fasta \
    -r reference/chr22.fasta \
    -o results/quast_pe_ref \
    --threads 8 \
    --min-contig 500 \
    --labels "SPAdes_PE" \
    --features reference/chr22.gff3
```

**Key QUAST outputs to check:**

```bash
# Open HTML report
firefox results/quast_pe/report.html

# Or check text report
cat results/quast_pe/report.txt
```

**What to look for:**
- **Genome fraction (with reference):** Should be >95%
- **Misassemblies:** Lower is better, <10 for chr22
- **Mismatches per 100kb:** Should be <100
- **Indels per 100kb:** Should be <10

### BUSCO: Biological Completeness

BUSCO checks for presence of universal single-copy orthologs. It's a biological quality metric.

```bash
busco \
    -i assembly/spades_pe/contigs.fasta \
    -o results/busco_pe \
    -m genome \
    -l primates_odb10 \
    --cpu 8 \
    --offline
```

**Parameter choices:**

- `-l primates_odb10`: Lineage-specific database
  - Use `primates_odb10` for human/ape genomes
  - Use `mammalia_odb10` for other mammals
  - Use `vertebrata_odb10` for broader comparison
- `-m genome`: Mode for genome assembly (vs transcriptome/proteins)

**Interpreting BUSCO results:**

```
Results:
    C:95.2%[S:94.8%,D:0.4%],F:2.1%,M:2.7%,n:13780

C = Complete (good)
    S = Single-copy (expected for diploid)
    D = Duplicated (indicates assembly issues if high)
F = Fragmented (partially recovered genes)
M = Missing (concerning if high)
```

**Good assembly:**
- Complete: >90%
- Duplicated: <5%
- Missing: <5%

**Poor assembly:**
- Complete: <80%
- Missing: >10%
- Duplicated: >10% (indicates haplotype duplication or contamination)

### Compare SE vs PE Assemblies

```bash
# Run QUAST on both
quast.py \
    assembly/spades_pe/contigs.fasta \
    assembly/spades_se/contigs.fasta \
    -o results/quast_comparison \
    --threads 8 \
    --labels "Paired-End,Single-End"
```

**Expected differences:**
- PE will have longer N50 (typically 2-5× longer)
- PE will have fewer contigs
- PE will have fewer misassemblies
- SE may have similar total length but more fragmented

---

## 9. Scaffolding and Gap Filling

### Why Scaffold?

After initial assembly, you have contigs (continuous sequences). Scaffolding:
- Orders and orients contigs
- Estimates gaps between contigs
- Uses paired-end information or long reads
- Creates scaffolds (ordered contigs with gaps)

**Only needed if:**
- You have additional data (mate-pairs, long reads, optical maps)
- You need chromosome-level assembly
- Draft assembly is too fragmented

### SSPACE: Paired-End Scaffolding

```bash
# SSPACE uses PE reads to scaffold contigs
perl SSPACE_Standard_v3.0.pl \
    -l libraries.txt \
    -s assembly/spades_pe/contigs.fasta \
    -x 1 \
    -m 32 \
    -o 20 \
    -t 8 \
    -k 5 \
    -a 0.7 \
    -n 15 \
    -p 0 \
    -v 0 \
    -z 0 \
    -g 0 \
    -T 8 \
    -b scaffolds_sspace
```

**libraries.txt format:**
```
lib1 bowtie trimmed/SRR622461_1.trim.fastq.gz trimmed/SRR622461_2.trim.fastq.gz 400 0.25 FR
```

**Parameters:**
- `-x 1`: Extend contigs (recommended)
- `-m 32`: Minimum overlap for merging
- `-k 5`: Minimum links to create scaffold
- `-a 0.7`: Maximum link ratio for reliable scaffold

**Pros:**
- Can dramatically improve N50
- Uses information already in your data

**Cons:**
- Can introduce errors if PE insert size is variable
- May create false scaffolds in repetitive regions

### Gap Filling with GapCloser

After scaffolding, you have N's representing gaps. Gap filling attempts to close these.

```bash
GapCloser \
    -a scaffolds_sspace.fasta \
    -b config.txt \
    -o assembly_gapfilled.fasta \
    -l 150 \
    -t 8
```

**config.txt:**
```
[LIB]
avg_ins=400
reverse_seq=0
asm_flags=3
rank=1
q1=trimmed/SRR622461_1.trim.fastq.gz
q2=trimmed/SRR622461_2.trim.fastq.gz
```

**When to skip scaffolding/gap filling:**
- If initial assembly already has good N50 (>100 kb for chr22)
- If you don't have additional data
- If assembly will be immediately mapped to reference anyway
- Time/resource constraints

---

## 10. Final Validation

### Map Reads Back to Assembly

Critical sanity check: do your reads map back to your assembly?

```bash
# Index assembly
bwa index assembly/spades_pe/contigs.fasta

# Map reads
bwa mem -t 16 \
    assembly/spades_pe/contigs.fasta \
    trimmed/SRR622461_1.trim.fastq.gz \
    trimmed/SRR622461_2.trim.fastq.gz \
    | samtools view -bS - \
    | samtools sort -@ 8 -o results/mapped.bam

# Index BAM
samtools index results/mapped.bam

# Calculate mapping statistics
samtools flagstat results/mapped.bam > results/mapping_stats.txt
```

**Good assembly should have:**
- >95% reads mapped
- >90% properly paired (for PE data)
- <1% singletons

**If mapping rate is low (<80%):**
- Assembly is incomplete
- Possible contamination
- Wrong organism

### Assembly Statistics Summary

```bash
# Custom script to get basic stats
python3 << 'EOF'
from Bio import SeqIO
import sys

fasta_file = "assembly/spades_pe/contigs.fasta"

contigs = list(SeqIO.parse(fasta_file, "fasta"))
lengths = sorted([len(c) for c in contigs], reverse=True)

total_length = sum(lengths)
num_contigs = len(lengths)
longest = lengths[0]

# Calculate N50
cumsum = 0
n50 = 0
for length in lengths:
    cumsum += length
    if cumsum >= total_length / 2:
        n50 = length
        break

print(f"Total contigs: {num_contigs}")
print(f"Total length: {total_length:,} bp")
print(f"Longest contig: {longest:,} bp")
print(f"N50: {n50:,} bp")
print(f"Mean length: {total_length // num_contigs:,} bp")
EOF
```

### Final Quality Checklist

- [ ] FastQC shows good quality (>Q30 median)
- [ ] >80% reads retained after trimming
- [ ] Assembly size matches expected genome size (±10%)
- [ ] N50 >50 kb for chr22 (>1 Mb for full genome)
- [ ] BUSCO completeness >90%
- [ ] QUAST misassemblies <5 per Mb
- [ ] >95% reads map back to assembly
- [ ] No obvious contamination (check BLAST top hit)

---

## Complete Reproducible Workflow Script

Here's a complete bash script you can run:

```bash
#!/bin/bash
set -euo pipefail

# Configuration
THREADS=16
MEMORY=100
PROJECT="genome_assembly"
SAMPLE="SRR622461"

# Create directory structure
mkdir -p ${PROJECT}/{raw_data,qc,trimmed,assembly,results}
cd ${PROJECT}

echo "=== Step 1: Download Data ==="
wget -P raw_data/ \
    ftp://ftp.sra.ebi.ac.uk/vol1/fastq/SRR622/${SAMPLE}/${SAMPLE}_1.fastq.gz \
    ftp://ftp.sra.ebi.ac.uk/vol1/fastq/SRR622/${SAMPLE}/${SAMPLE}_2.fastq.gz

echo "=== Step 2: Quality Control (Pre-trim) ==="
fastqc -t ${THREADS} -o qc/ raw_data/${SAMPLE}_*.fastq.gz
multiqc qc/ -o qc/ --filename multiqc_pretrim

echo "=== Step 3: Trimming and Filtering ==="
fastp \
    -i raw_data/${SAMPLE}_1.fastq.gz \
    -I raw_data/${SAMPLE}_2.fastq.gz \
    -o trimmed/${SAMPLE}_1.trim.fastq.gz \
    -O trimmed/${SAMPLE}_2.trim.fastq.gz \
    --detect_adapter_for_pe \
    --qualified_quality_phred 20 \
    --unqualified_percent_limit 40 \
    --length_required 50 \
    --thread ${THREADS} \
    --html trimmed/fastp_report.html \
    --json trimmed/fastp_report.json

echo "=== Step 4: Quality Control (Post-trim) ==="
fastqc -t ${THREADS} -o qc/ trimmed/${SAMPLE}_*.trim.fastq.gz
multiqc qc/ -o qc/ --filename multiqc_posttrim

echo "=== Step 5: Genome Assembly ==="
spades.py \
    -1 trimmed/${SAMPLE}_1.trim.fastq.gz \
    -2 trimmed/${SAMPLE}_2.trim.fastq.gz \
    -o assembly/spades_pe \
    --threads ${THREADS} \
    --memory ${MEMORY} \
    -k 21,33,55,77 \
    --careful

echo "=== Step 6: Assembly Quality Assessment ==="
# QUAST
quast.py \
    assembly/spades_pe/contigs.fasta \
    -o results/quast \
    --threads ${THREADS} \
    --min-contig 500 \
    --labels "SPAdes_PE"

# BUSCO
busco \
    -i assembly/spades_pe/contigs.fasta \
    -o results/busco \
    -m genome \
    -l primates_odb10 \
    --cpu ${THREADS}

echo "=== Step 7: Read Mapping Validation ==="
bwa index assembly/spades_pe/contigs.fasta
bwa mem -t ${THREADS} \
    assembly/spades_pe/contigs.fasta \
    trimmed/${SAMPLE}_1.trim.fastq.gz \
    trimmed/${SAMPLE}_2.trim.fastq.gz \
    | samtools view -bS - \
    | samtools sort -@ ${THREADS} -o results/mapped.bam
samtools index results/mapped.bam
samtools flagstat results/mapped.bam > results/mapping_stats.txt

echo "=== Assembly Complete ==="
echo "Results summary:"
echo "- Assembly: assembly/spades_pe/contigs.fasta"
echo "- QUAST report: results/quast/report.html"
echo "- BUSCO report: results/busco/short_summary.txt"
echo "- Mapping stats: results/mapping_stats.txt"
```

---

## Troubleshooting Common Issues

### Issue 1: SPAdes Crashes with Memory Error

**Symptoms:**
```
== Error == system call for: "[bwa]" failed
```

**Solutions:**
1. Reduce memory: `--memory 80`
2. Use MEGAHIT
```bash
# Switch to MEGAHIT if memory constrained
megahit \
    -1 trimmed/${SAMPLE}_1.trim.fastq.gz \
    -2 trimmed/${SAMPLE}_2.trim.fastq.gz \
    -o assembly/megahit_pe \
    --threads 16 \
    --memory 0.5  # Use 50% of available RAM
```

3. Reduce coverage by subsampling:
```bash
# Keep 50% of reads randomly
seqtk sample -s100 trimmed/${SAMPLE}_1.trim.fastq.gz 0.5 > trimmed/${SAMPLE}_1.sub.fastq
seqtk sample -s100 trimmed/${SAMPLE}_2.trim.fastq.gz 0.5 > trimmed/${SAMPLE}_2.sub.fastq
gzip trimmed/${SAMPLE}_*.sub.fastq
```

### Issue 2: Very Fragmented Assembly (N50 < 10kb)

**Possible causes:**
- Low coverage (<20×)
- Poor quality data
- Highly repetitive genome
- Wrong k-mer sizes

**Diagnosis:**
```bash
# Check coverage
grep "Average coverage" assembly/spades_pe/contigs.paths

# Check read quality
grep "percent_duplication" trimmed/fastp_report.json
```

**Solutions:**

1. **Adjust k-mer range:**
```bash
# For low coverage, use smaller k-mers
spades.py ... -k 21,33,55

# For high coverage, use larger k-mers
spades.py ... -k 33,55,77,99,127
```

2. **Error correction more aggressive:**
```bash
# Use standalone error corrector first
lighter -r trimmed/${SAMPLE}_1.trim.fastq.gz \
        -r trimmed/${SAMPLE}_2.trim.fastq.gz \
        -K 32 13000000 \
        -od corrected/
```

3. **Try different assembler:**
```bash
# ABySS handles repeats differently
abyss-pe name=chr22 k=64 \
    in='trimmed/${SAMPLE}_1.trim.fastq.gz trimmed/${SAMPLE}_2.trim.fastq.gz' \
    np=${THREADS}
```

### Issue 3: Assembly Much Larger Than Expected

**Symptoms:**
- Expected: 51 Mb (chr22)
- Got: 75 Mb

**Causes:**
- Contamination
- Diploid assembly (both haplotypes assembled separately)
- Unfiltered duplications

**Diagnosis:**
```bash
# BLAST top contigs to check for contamination
blastn -query assembly/spades_pe/contigs.fasta \
       -db nt \
       -remote \
       -max_target_seqs 5 \
       -outfmt "6 qseqid sseqid pident length staxids" \
       -out results/blast_check.txt \
       -num_threads 8

# Check for duplications
dedupe.sh in=assembly/spades_pe/contigs.fasta \
          out=assembly/deduplicated.fasta
```

**Solutions:**

1. **Remove contaminants:**
```bash
# Filter by taxonomy
# Keep only human sequences (taxid:9606)
# Use tool like blobtools for visualization
```

2. **Purge haplotigs (if diploid duplication):**
```bash
# Purge_haplotigs removes heterozygous duplications
minimap2 -ax map-pb assembly/spades_pe/contigs.fasta \
    long_reads.fastq > aligned.sam
purge_haplotigs hist -b aligned.bam -g assembly.fasta
purge_haplotigs cov -i aligned.bam.gencov -o coverage_stats.csv
purge_haplotigs purge -g assembly.fasta -c coverage_stats.csv
```

### Issue 4: Low Read Mapping Rate (<90%)

**Diagnosis:**
```bash
samtools flagstat results/mapped.bam
# Check for high unmapped percentage
```

**Causes & Solutions:**

1. **Adapter contamination still present:**
```bash
# More aggressive adapter trimming
fastp ... --cut_right --cut_right_window_size 4 --cut_right_mean_quality 20
```

2. **Assembly incomplete:**
```bash
# Check if unmapped reads form additional contigs
samtools view -f 4 results/mapped.bam | \
    samtools fastq - > unmapped.fastq

# Assemble unmapped reads
spades.py -s unmapped.fastq -o assembly/unmapped_rescue
```

3. **Contamination in reads:**
```bash
# Screen for contamination before assembly
kraken2 --db standard \
        --threads 16 \
        --paired \
        trimmed/${SAMPLE}_1.trim.fastq.gz \
        trimmed/${SAMPLE}_2.trim.fastq.gz \
        --report kraken_report.txt \
        --classified-out classified#.fastq \
        --unclassified-out unclassified#.fastq
```

### Issue 5: SPAdes Stalls at Graph Construction

**Symptoms:**
- Process runs for >48 hours
- High memory usage but no progress
- Log shows stuck at "Constructing de Bruijn graph"

**Solutions:**

1. **Reduce k-mer complexity:**
```bash
# Skip largest k-mer
spades.py ... -k 21,33,55  # instead of 21,33,55,77
```

2. **Use --meta mode for complex samples:**
```bash
# Meta mode uses different graph simplification
spades.py ... --meta
```

3. **Pre-filter low-complexity reads:**
```bash
# Remove low complexity sequences
bbduk.sh in=trimmed/${SAMPLE}_1.trim.fastq.gz \
         in2=trimmed/${SAMPLE}_2.trim.fastq.gz \
         out=filtered_1.fastq.gz \
         out2=filtered_2.fastq.gz \
         entropy=0.7 \
         entropywindow=50
```

---

## Advanced Topics

### A. Haplotype-Aware Assembly

For diploid genomes, you may want to assemble both haplotypes separately.

**Why?**
- Standard assemblers collapse haplotypes
- Lose heterozygous information
- Important for structural variant detection

**Tools:**

1. **FALCON-Unzip** (requires long reads):
```bash
# Best for PacBio data
# Produces primary and alternate haplotigs
fc_run.py fc_unzip.cfg
```

2. **Supernova** (10X Genomics linked-reads):
```bash
supernova run --id=assembly \
              --fastqs=linked_reads/ \
              --maxreads=1200000000
```

3. **HiFiasm** (PacBio HiFi):
```bash
# State-of-the-art for haplotype resolution
hifiasm -o output -t 32 hifi_reads.fastq.gz
```

**For Illumina-only data:**
- Standard assemblers will collapse haplotypes
- Accept this limitation or add long-read data
- Platanus-allee attempts haplotype separation with PE data

### B. Polishing Assemblies

After assembly, polish to fix small errors.

**Short-read polishing:**

```bash
# Pilon: corrects SNPs and small indels
# Requires mapped reads (BAM file)

# Map reads to assembly (if not done already)
bwa mem -t 16 assembly/spades_pe/contigs.fasta \
    trimmed/${SAMPLE}_1.trim.fastq.gz \
    trimmed/${SAMPLE}_2.trim.fastq.gz \
    | samtools sort -@ 8 -o mapped.bam

samtools index mapped.bam

# Run Pilon
pilon --genome assembly/spades_pe/contigs.fasta \
      --frags mapped.bam \
      --output polished \
      --changes \
      --threads 16
```

**Typical improvements:**
- 10-100 SNP corrections per Mb
- 5-50 small indel corrections per Mb
- No change to contiguity (N50 stays same)

**When to polish:**
- Publication-quality assemblies
- When downstream analysis is SNP-sensitive
- After consensus calling

**When to skip:**
- Draft assemblies
- Time/resource constraints
- Assembly will be immediately aligned to reference

**Long-read polishing:**

```bash
# Racon: fast, uses long reads
racon -t 16 \
      long_reads.fastq \
      mapped.paf \
      assembly.fasta > polished.fasta

# Medaka: Nanopore-specific, higher accuracy
medaka_consensus -i long_reads.fastq \
                 -d assembly.fasta \
                 -o medaka_output \
                 -t 16
```

### C. Optimizing for Specific Scenarios

#### Scenario 1: Low Coverage Data (10-20×)

**Challenges:**
- Insufficient overlap information
- More gaps in assembly
- Lower confidence base calls

**Optimizations:**
```bash
# Use smaller k-mers only
spades.py ... -k 21,33,55

# Use --only-assembler to skip error correction
# (error correction needs higher coverage)
spades.py ... --only-assembler

# Alternative: Digital normalization first
bbnorm.sh in=reads.fastq out=normalized.fastq \
          target=40 min=5
```

#### Scenario 2: High Coverage Data (>100×)

**Challenges:**
- Excessive memory usage
- Slower runtime
- Diminishing returns

**Optimizations:**
```bash
# Downsample to optimal coverage (50-80×)
# Use seqtk
seqtk sample -s100 reads.fastq.gz 0.5 > downsampled.fastq

# Or use BBNorm for intelligent normalization
bbnorm.sh in=reads.fastq out=normalized.fastq \
          target=80 min=5
```

#### Scenario 3: Repetitive Genome Regions

**Challenges:**
- Repeats longer than read length collapse
- Ambiguous paths through graph
- Fragmented assembly

**Optimizations:**
```bash
# Use largest possible k-mers
spades.py ... -k 55,77,99,127

# Add mate-pair libraries (longer insert size)
spades.py -1 pe1.fq -2 pe2.fq \
          --mp1-1 mp1.fq --mp1-2 mp2.fq \
          --mp1-or fr  # orientation

# Or use long reads for scaffolding
spades.py --pe1-1 short1.fq --pe1-2 short2.fq \
          --nanopore long.fq
```

#### Scenario 4: Contaminated Samples

**Pre-assembly decontamination:**

```bash
# 1. Identify contaminants with Kraken2
kraken2 --db minikraken \
        --threads 16 \
        --paired \
        reads_1.fq reads_2.fq \
        --report kraken_report.txt \
        --output kraken_output.txt

# 2. Extract taxonomy
# Keep only taxid 9606 (Homo sapiens)
extract_kraken_reads.py \
    -k kraken_output.txt \
    -s1 reads_1.fq -s2 reads_2.fq \
    -o clean_1.fq -o2 clean_2.fq \
    -t 9606 --include-children

# 3. Assemble cleaned reads
spades.py -1 clean_1.fq -2 clean_2.fq ...
```

**Post-assembly decontamination:**

```bash
# BLAST contigs to identify non-target sequences
blastn -query contigs.fasta \
       -db nt \
       -max_target_seqs 1 \
       -outfmt "6 qseqid staxids" \
       -out blast_tax.txt

# Filter contigs by taxonomy
# Keep only human contigs (implementation depends on your needs)
```

---

## Comparative Analysis: SE vs PE Assembly

Let's compare the expected outcomes:

### Metrics Comparison Table

| Metric | Single-End | Paired-End | Improvement |
|--------|-----------|------------|-------------|
| **N50** | 5-15 kb | 50-150 kb | **10-15× longer** |
| **Number of contigs** | 10,000-50,000 | 1,000-5,000 | **10× fewer** |
| **Largest contig** | 50-200 kb | 500 kb - 5 Mb | **10-25× longer** |
| **Misassemblies** | High (10-50 per Mb) | Low (1-5 per Mb) | **5-10× fewer** |
| **Repeat resolution** | Poor | Good | **Qualitative** |
| **Runtime** | 6-12 hours | 12-24 hours | 2× slower |
| **Memory usage** | 50-100 GB | 100-200 GB | 2× more |
| **Cost per gigabase** | $15-30 | $30-60 | 2× more expensive |

### When to Use Each

**Use Single-End when:**
- Extreme budget constraints
- Only need presence/absence information
- Genome is simple (bacterial, no repeats)
- Pilot study or proof-of-concept
- **Not recommended for human genome**

**Use Paired-End when:**
- Need quality assembly
- Studying eukaryotic genomes
- Detecting structural variants
- Publication-quality results
- **Always for human genome**

---

## Performance Benchmarking

### Expected Runtimes (Human Chr22, 30× coverage)

**Hardware: 32 cores, 256 GB RAM, SSD storage**

| Step | SE Runtime | PE Runtime | Notes |
|------|-----------|------------|-------|
| FastQC | 15 min | 30 min | I/O bound |
| Trimming | 20 min | 40 min | Highly parallel |
| SPAdes assembly | 8 hours | 18 hours | Memory intensive |
| MEGAHIT assembly | 2 hours | 4 hours | Faster alternative |
| QUAST | 10 min | 15 min | Quick |
| BUSCO | 2 hours | 2 hours | Same |
| Read mapping | 1 hour | 2 hours | Parallel |
| **Total (SPAdes)** | **~12 hours** | **~24 hours** | |
| **Total (MEGAHIT)** | **~6 hours** | **~8 hours** | |

### Storage Requirements

```
raw_data/           30-50 GB    (FASTQ files)
trimmed/            25-40 GB    (trimmed FASTQ)
assembly/
  ├── spades_pe/    150-300 GB  (intermediate files)
  │   ├── K21/      30-50 GB
  │   ├── K33/      40-70 GB
  │   ├── K55/      50-100 GB
  │   └── K77/      30-80 GB
  └── contigs.fasta 50-100 MB   (final assembly)
qc/                 500 MB      (QC reports)
results/            10-20 GB    (BAM files, reports)

Total peak:         200-400 GB
After cleanup:      30-60 GB
```

**Cleanup strategy:**
```bash
# After successful assembly, remove intermediate files
rm -rf assembly/spades_pe/K*/
rm -rf assembly/spades_pe/tmp/
rm -rf assembly/spades_pe/corrected/

# Keep only essential files
# - contigs.fasta
# - scaffolds.fasta
# - spades.log
# - contigs.paths
```

---

## Validation with Reference Genome

If you have a reference genome (common for model organisms):

### Whole-Genome Alignment

```bash
# Using MUMmer for whole-genome alignment
nucmer --maxmatch --prefix=aln \
       reference/chr22.fasta \
       assembly/spades_pe/contigs.fasta

# Filter alignments
delta-filter -r -q aln.delta > aln.filtered.delta

# Generate alignment statistics
dnadiff -d aln.filtered.delta -p comparison

# Visualize with mummerplot
mummerplot --png --prefix=alignment \
           --layout \
           aln.filtered.delta
```

**Key output files:**
- `comparison.report`: Overall statistics
- `comparison.1delta`: Alignment coordinates
- `alignment.png`: Visual alignment plot

**Metrics to check:**
- **AvgIdentity:** Should be >99.5% for same organism
- **TotalSNPs:** Variations from reference
- **TotalIndels:** Small insertions/deletions
- **Relocation events:** Structural rearrangements

### Variant Calling Against Reference

```bash
# Map assembly to reference
minimap2 -ax asm5 \
         reference/chr22.fasta \
         assembly/spades_pe/contigs.fasta \
         | samtools sort -o assembly_vs_ref.bam

samtools index assembly_vs_ref.bam

# Call variants
bcftools mpileup -f reference/chr22.fasta \
                 assembly_vs_ref.bam \
    | bcftools call -mv -Oz -o variants.vcf.gz

# Filter quality
bcftools view -i 'QUAL>30' variants.vcf.gz > filtered_variants.vcf

# Statistics
bcftools stats filtered_variants.vcf > variant_stats.txt
```

**Expected variant counts (if same individual):**
- SNPs: ~1 per 1000 bp (polymorphisms)
- Small indels: ~0.1 per 1000 bp
- Structural variants: ~1 per 10,000 bp

**If significantly different:**
- Different strain/individual (expected)
- Assembly errors (concerning)
- Reference errors (rare but possible)

---

## Best Practices Summary

### Do's ✅

1. **Always run QC before and after trimming**
   - Catches data quality issues early
   - Validates trimming parameters

2. **Use paired-end data for eukaryotes**
   - Vastly superior assembly quality
   - Worth the extra cost

3. **Choose k-mers based on read length**
   - Never exceed read length
   - Use multiple k-mers iteratively

4. **Validate with multiple metrics**
   - QUAST: statistical quality
   - BUSCO: biological completeness
   - Read mapping: technical accuracy

5. **Document your workflow**
   - Save command lines
   - Record software versions
   - Note parameter choices

6. **Keep intermediate files during development**
   - Restart from failures
   - Compare different parameter sets

### Don'ts ❌

1. **Don't skip quality control**
   - Bad input = bad output
   - Assemblers can't fix fundamentally bad data

2. **Don't use arbitrary parameters**
   - Understand what each parameter does
   - Tune for your specific dataset

3. **Don't trust a single quality metric**
   - N50 alone is misleading
   - High N50 with low BUSCO = bad assembly

4. **Don't assemble without sufficient coverage**
   - <20× coverage = poor assembly
   - Get more data rather than fight bad assembly

5. **Don't forget about computational limits**
   - Human genome needs serious hardware
   - Plan resources before starting

6. **Don't ignore biological validation**
   - BUSCO and mapping statistics matter
   - Annotate key genes to verify correctness

---

## Extending This Workflow

### Adding Long-Read Data

Modern best practice combines short and long reads:

```bash
# Hybrid assembly with SPAdes
spades.py \
    --pe1-1 illumina_R1.fastq.gz \
    --pe1-2 illumina_R2.fastq.gz \
    --nanopore nanopore_reads.fastq.gz \
    -o assembly/hybrid \
    --threads 32 \
    --memory 250 \
    -k 21,33,55,77

# Or long-read first, then polish with short reads
# 1. Assemble long reads
flye --nano-raw nanopore_reads.fastq.gz \
     --out-dir assembly/flye \
     --threads 32 \
     --genome-size 3g

# 2. Polish with short reads
bwa index assembly/flye/assembly.fasta
bwa mem assembly/flye/assembly.fasta \
    illumina_R1.fastq.gz illumina_R2.fastq.gz \
    | samtools sort -o mapped.bam

pilon --genome assembly/flye/assembly.fasta \
      --frags mapped.bam \
      --output polished
```

### Genome Annotation

After assembly, annotate to identify genes:

```bash
# Augustus for gene prediction
augustus --species=human \
         --gff3=on \
         assembly/contigs.fasta \
         > genes.gff3

# Or MAKER pipeline (comprehensive)
maker -CTL  # Generate control files
# Edit control files with your data
maker       # Run annotation
```

### Structural Variant Detection

```bash
# Detect SVs by comparing to reference
sniffles --mapped_reads mapped.bam \
         --vcf structural_variants.vcf \
         --threads 16

# Or assembly-based SV calling
assemblytics ref.fasta assembly.fasta output_prefix
```

---

## Troubleshooting Decision Tree

```
Assembly Quality Poor?
├── Low N50 (<10 kb)?
│   ├── Coverage <20×? → Get more data
│   ├── Poor read quality? → Re-trim with stricter parameters
│   ├── Highly repetitive? → Use longer reads or larger k-mers
│   └── Wrong assembler? → Try MEGAHIT or ABySS
│
├── High contig count (>50,000)?
│   ├── Low coverage? → Get more data or normalize
│   ├── Contamination? → Decontaminate before assembly
│   ├── Heterozygosity? → Use haplotype-aware assembler
│   └── Over-correction? → Use --only-assembler mode
│
├── Low BUSCO (<80%)?
│   ├── Wrong lineage? → Check BUSCO database choice
│   ├── Fragmented assembly? → Check N50 and fix that first
│   ├── Incomplete coverage? → Check for coverage gaps
│   └── Wrong organism? → Verify sample identity
│
├── Low mapping rate (<90%)?
│   ├── Adapters present? → Re-trim more aggressively
│   ├── Contamination? → Filter reads pre-assembly
│   ├── Incomplete assembly? → Check coverage uniformity
│   └── Wrong sample? → Verify sample identity
│
└── High misassemblies (>10 per Mb)?
    ├── Repeats misresolved? → Use paired-end or long reads
    ├── Chimeric reads? → Filter PCR duplicates
    ├── Wrong parameters? → Adjust k-mer sizes
    └── Bad reference? → Validate reference quality
```

---

## Real-World Example Results

Here's what you should expect for human chromosome 22:

### Good Assembly (Paired-End, 50× coverage)

```
QUAST Statistics:
  Contigs: 423
  Largest contig: 2,847,193 bp
  Total length: 51,234,567 bp
  N50: 284,719 bp
  L50: 52
  GC content: 47.92%
  
BUSCO (primates_odb10):
  Complete: 95.4% [S:94.8%, D:0.6%]
  Fragmented: 2.3%
  Missing: 2.3%
  
Read Mapping:
  Mapped: 98.2%
  Properly paired: 96.8%
  Singletons: 1.4%
```

### Poor Assembly (Single-End, 15× coverage)

```
QUAST Statistics:
  Contigs: 18,742
  Largest contig: 124,563 bp
  Total length: 47,892,341 bp
  N50: 8,432 bp
  L50: 1,247
  GC content: 48.14%
  
BUSCO (primates_odb10):
  Complete: 78.2% [S:77.1%, D:1.1%]
  Fragmented: 12.4%
  Missing: 9.4%
  
Read Mapping:
  Mapped: 91.3%
  Properly paired: N/A (single-end)
  Unmapped: 8.7%
```

---

## Conclusion

This tutorial covered a complete, reproducible workflow for human genome reconstruction. Key takeaways:

1. **Paired-end data is essential** for quality eukaryotic assemblies
2. **Quality control at every step** prevents wasting time on bad data
3. **Parameter tuning matters** - understand your tools
4. **Multiple validation metrics** give confidence in results
5. **Computational resources are significant** - plan accordingly

### Next Steps

After completing this tutorial, you should:

1. **Practice with the provided example** (chr22 data)
2. **Scale to full genome** once comfortable
3. **Explore hybrid assembly** if you have long-read data
4. **Integrate with downstream analysis** (annotation, variant calling)

### Additional Resources

- **SPAdes manual:** https://github.com/ablab/spades
- **QUAST docs:** http://quast.sourceforge.net/
- **BUSCO guide:** https://busco.ezlab.org/
- **Genome assembly workshop:** https://training.galaxyproject.org/training-material/topics/assembly/

### Citation

If using this workflow, cite the key tools:
- SPAdes: Bankevich et al. (2012) J Comput Biol
- QUAST: Gurevich et al. (2013) Bioinformatics
- BUSCO: Simão et al. (2015) Bioinformatics
- fastp: Chen et al. (2018) Bioinformatics

---

**Questions or issues? The key to successful genome assembly is understanding your data, choosing appropriate tools, and validating results thoroughly. Good luck with your assemblies!**
